Apache Spark Book Crossing Analysis
Skills Required: Apache Spark SQL, Apache Hive
Description:
This case study is used to analyze Book Crossing Data set which has details about books, ratings and users.
Input Data
http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip
BX-Books.csv
ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher
BX-Book-Ratings.csv
User-ID ISBN Book-Rating
BX-Users.csv
User-ID Location Age
Requirement
Create tables in hive and store the data related to Books, Book-Ratings and Users in Parquet format.
Use Apache Spark SQL to query the hive tables and perform the following analysis.
Store the output of the analysis into hive tables.
a. Find the most popular Author among each of the following age groups:
less than 10 years
10 to 18 years
19 to 35 years
36 to 45 years
46 years and above
The most popular author is one who got highest number of ratings >= 6
b. Find the Most Popular Author in each Country
c. Find the state in each country which has the highest number of readers




------------------------------------SOLUTION----------------------------


--------------------------------USE CASE BOOK ANALYSIS---------------------------------

Step1: Creation of tables in Hive


CREATE DATABASE DB_BOOK1

CREATE OR REPLACE TABLE BOOK_DETAILS (ISBN STRING,BOOK_TITLE STRING,BOOK_AUTHOR STRING,YOP INT,PUBLISHER STRING)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS PARQUET
TBLPROPERTIES("skip.header.line.count"="1");

LOAD DATA LOCAL INPATH 'PATH' INTO TABLE BOOK_DETAILS;

CREATE OR REPLACE TABLE BOOK_RATING (USER_ID STRING,ISBN STRING,BOOK_RATINGS INT)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS PARQUET
TBLPROPERTIES("skip.header.line.count"="1");

LOAD DATA LOCAL INPATH 'PATH' INTO TABLE BOOK_RATING;


CREATE OR REPLACE TABLE USER_DETAILS (USER_ID STRING,LOCATION STRING,AGE INT)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS PARQUET
TBLPROPERTIES("skip.header.line.count"="1");

LOAD DATA LOCAL INPATH 'PATH' INTO TABLE BOOK_RATING;

//Configuration of Hive is done by placing your hive-site.xml file in conf/.

spark.hql("""select book_author,,max(count(book_author)) as counts,case when age>9 then "child" 
						 when 10<=age<=18 then "teenager"
						 when 19<=age<=35 then "millenials"
						 when 36<=age<=45 then "middleage"
						 else "senior"
					end as age_group from book_details bd,book_rating br,user_details ud where 
					bd.isbn=br.isbn and br.user_id=ud.user_id group by (,case when age>9 then "child" 
						 when 10<=age<=18 then "teenager"
						 when 19<=age<=35 then "millenials"
						 when 36<=age<=45 then "middleage"
						 else "senior"
					end) order by counts""")
					
					
					
					
spark.hql("""select book_author,location,max(count(book_author)) as counts from book_details bd,book_rating br,user_details ud where 
					bd.isbn=br.isbn and br.user_id=ud.user_id  group by location""")


					

